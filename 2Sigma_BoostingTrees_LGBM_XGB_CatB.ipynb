{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.competitions import twosigmanews\n",
    "import catboost as catb\n",
    "from catboost import CatBoostClassifier\n",
    "from datetime import datetime, date\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from resource import getrusage, RUSAGE_SELF\n",
    "from sklearn import model_selection\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "np.random.seed(1) # I don't know if using numpy random seeding helps in reproducing results but I do it anyways to be safe\n",
    "\n",
    "global STARTED_TIME\n",
    "STARTED_TIME = datetime.now()\n",
    "\n",
    "global N_THREADS\n",
    "N_THREADS = multiprocessing.cpu_count() * 2 \n",
    "\n",
    "print(f'N_THREADS: {N_THREADS}')\n",
    "N_THREADS: 8\n",
    "global N_WINDOW, BASE_FEATURES\n",
    "\n",
    "N_WINDOW = np.sort([5, 10, 20, 252])\n",
    "\n",
    "# Features for lags calculation\n",
    "BASE_FEATURES = [\n",
    "    'returnsOpenPrevMktres10',\n",
    "    'returnsOpenPrevRaw10',\n",
    "    'open',\n",
    "    'close']\n",
    "Generate features with the usual window statics (mean, median, max, min, exponentially weighted mean).\n",
    "\n",
    "global FILLNA\n",
    "FILLNA = -99999\n",
    "\n",
    "ewm = pd.Series.ewm\n",
    "\n",
    "def generate_features_for_df_by_assetCode(df_by_code):\n",
    "    prevlag = 1\n",
    "    for window in N_WINDOW:\n",
    "        rolled = df_by_code[BASE_FEATURES].shift(prevlag).rolling(window=window)\n",
    "        df_by_code = df_by_code.join(rolled.mean().add_suffix(f'_window_{window}_mean'))\n",
    "        df_by_code = df_by_code.join(rolled.median().add_suffix(f'_window_{window}_median'))\n",
    "        df_by_code = df_by_code.join(rolled.max().add_suffix(f'_window_{window}_max'))\n",
    "        df_by_code = df_by_code.join(rolled.min().add_suffix(f'_window_{window}_min'))\n",
    "        for col in BASE_FEATURES: # not sure if this can be optimized without using for loop but I only know how to calculate exponentially moving averages like this\n",
    "            df_by_code[col + f'_window_{window}_ewm'] = ewm(df_by_code[col], span=window).mean().add_suffix(f'_window_{window}_ewm')\n",
    "    return df_by_code.fillna(FILLNA)\n",
    "\n",
    "def generate_features(df):\n",
    "    global BASE_FEATURES, N_THREADS\n",
    "    all_df = []\n",
    "    df_codes = df.groupby('assetCode')\n",
    "    df_codes = [df_code[1][['time','assetCode'] + BASE_FEATURES] for df_code in df_codes]\n",
    "    pool = Pool(N_THREADS)\n",
    "    all_df = pool.map(generate_features_for_df_by_assetCode, df_codes)\n",
    "    new_df = pd.concat(all_df)\n",
    "    new_df.drop(BASE_FEATURES,axis=1,inplace=True)\n",
    "    pool.close()\n",
    "    return new_df\n",
    "\n",
    "# The following functions are used for initialization and expanding of numpy arrays\n",
    "# for storing historical data of all assets.\n",
    "\n",
    "# It helps to have very fast lags creation.\n",
    "\n",
    "# Initialization of history array\n",
    "def initialize_values(items=5000, features=4, history=15):\n",
    "    return np.ones((items, features, history))*np.nan\n",
    "\n",
    "# Expanding of history array for new assets\n",
    "def expand_history_array(history_array, items=100):\n",
    "    return np.concatenate([history_array, initialize_values(items, history_array.shape[1], history_array.shape[2])])\n",
    "\n",
    "# codes dictionary maps assetCode to the index in the history array\n",
    "# if we found new assetCode - we have to store it and expand history\n",
    "def get_index_by_assetCode(assetCode):\n",
    "    global code2array_idx, history\n",
    "    try: \n",
    "        return code2array_idx[assetCode]\n",
    "    except KeyError:\n",
    "        code2array_idx[assetCode] = len(code2array_idx)\n",
    "        if len(code2array_idx) > history.shape[0]:\n",
    "            history = expand_history_array(history, 100)\n",
    "        return code2array_idx[assetCode]\n",
    "\n",
    "# list2codes returns numpy array of indices of assetCodes in history array(for each day)\n",
    "def codes_list2idx_array(codes_list):\n",
    "    return np.array([get_index_by_assetCode(assetCode) for assetCode in codes_list])\n",
    "env = twosigmanews.make_env()\n",
    "Loading the data... This could take a minute.\n",
    "Done!\n",
    "(market_train_df, news_train_df) = env.get_training_data()\n",
    "# Memory limit 16GB leaves me no choice but to drop some columns early on.\n",
    "# Kernel crashes when all memory is used up.\n",
    "market_train_df = market_train_df.drop(['universe'], axis = 1)\n",
    "news_train_df = news_train_df.drop(['sourceTimestamp', 'sourceId', 'headline', 'takeSequence', \n",
    "                                    'provider', 'subjects', 'audiences', 'bodySize', \n",
    "                                    'companyCount', 'headlineTag', 'marketCommentary', 'sentenceCount', 'wordCount',\n",
    "                                    'relevance', 'sentimentWordCount', 'noveltyCount12H', 'noveltyCount24H',\n",
    "                                    'noveltyCount3D', 'noveltyCount5D', 'noveltyCount7D', 'volumeCounts12H',\n",
    "                                    'volumeCounts24H', 'volumeCounts3D', 'volumeCounts5D',\n",
    "                                    'volumeCounts7D'], axis = 1)\n",
    "\n",
    "# uncomment if you are not using news data\n",
    "# del news_train_df\n",
    "using('Data loaded')\n",
    "0:00:15 Data loaded max RSS 9.0Gib\n",
    "def process_time(df):\n",
    "    df['time'] = df['time'].dt.date\n",
    "    return df\n",
    "\n",
    "market_train_df = process_time(market_train_df)\n",
    "news_train_df = process_time(news_train_df)\n",
    "\n",
    "# Dataframe filtering\n",
    "print('DF Filtering')\n",
    "market_train_df = market_train_df.loc[market_train_df['time']>=FILTERDATE]\n",
    "news_train_df = news_train_df.loc[news_train_df['time']>=FILTERDATE]\n",
    "\n",
    "if SAMPLEDATE is not None:\n",
    "    market_train_df = market_train_df.loc[market_train_df['time']<=SAMPLEDATE]  \n",
    "    news_train_df = news_train_df.loc[news_train_df['time']<=SAMPLEDATE]  \n",
    "using('Done')\n",
    "DF Filtering\n",
    "0:00:22 Done max RSS 9.0Gib\n",
    "The first feature I think is interesting is ratio of a single asset's 'volume', 'close' to mean value of 'market'. Because all assets have different average volumes and closing price (I think in this regard, either one of open or close is usually enough). If single asset's 'volume'/'close''s ratio changes in relation to 'market_mean' it would be a possible indicator that implies an asset is oversold / overbought. Thus, we will include these ratios to base features.\n",
    "\n",
    "def add_market_mean_col(market_df):\n",
    "    daily_market_mean_df = market_df.groupby('time').mean()\n",
    "    daily_market_mean_df = daily_market_mean_df[['volume', 'close']]\n",
    "    merged_df = market_df.merge(daily_market_mean_df, left_on='time',\n",
    "                                right_index=True, suffixes=(\"\",'_market_mean'))\n",
    "    merged_df['volume/volume_market_mean'] = merged_df['volume'] / merged_df['volume_market_mean']\n",
    "    merged_df['close/close_market_mean'] = merged_df['close'] / merged_df['close_market_mean']\n",
    "    return merged_df.reset_index(drop = True)\n",
    "\n",
    "BASE_FEATURES = BASE_FEATURES + ['volume', 'volume/volume_market_mean', 'close/close_market_mean']\n",
    "\n",
    "market_train_df = add_market_mean_col(market_train_df)\n",
    "market_train_df.head(3)\n",
    "\n",
    "Most day traders would consider how much an asset price appreciated / depreciated on a single trading day is an important factor in trading.\n",
    "\n",
    "def generate_open_close_ratio(df):\n",
    "    df['open/close'] = df['open'] / df['close']\n",
    "    \n",
    "BASE_FEATURES = BASE_FEATURES + ['open/close']\n",
    "\n",
    "generate_open_close_ratio(market_train_df)\n",
    "\n",
    "#Raw return features themselves are not that meaningful (unlike market residual features) \n",
    "#because 1 dollar appreciation of an asset which has price of 5 and that of 100 have very \n",
    "#different implications. Raw return features ratio to 'open', 'close' might be more useful.\n",
    "\n",
    "open_raw_cols = ['returnsOpenPrevRaw1', 'returnsOpenPrevRaw10']\n",
    "close_raw_cols = ['returnsClosePrevRaw1', 'returnsClosePrevRaw10']\n",
    "\n",
    "def raw_features_to_ratio_features(df):\n",
    "    for col in open_raw_cols:\n",
    "        df[col + '/open' ] = df[col] / df['open']\n",
    "    for col in close_raw_cols:\n",
    "        df[col + '/close'] = df[col] / df['close']\n",
    "\n",
    "BASE_FEATURES = BASE_FEATURES + ['returnsClosePrevRaw1/close', 'returnsClosePrevRaw10/close', 'returnsOpenPrevRaw1/open', 'returnsOpenPrevRaw10/open']\n",
    "\n",
    "raw_features_to_ratio_features(market_train_df)\n",
    "market_train_df.head(3)\n",
    "\n",
    "#Not related to feature generations but I want to get rid of outliers (too much variations of price in one day). \n",
    "#Among the deleted rows, opening price 999.99 seems that it is a dummy value that was filled.\n",
    "\n",
    "origlen = len(market_train_df)\n",
    "print(market_train_df.loc[market_train_df['open/close'] >= 3][['open', 'close']])\n",
    "print(market_train_df.loc[market_train_df['open/close'] <= 0.3][['open', 'close']])\n",
    "market_train_df = market_train_df.loc[market_train_df['open/close'] < 3]\n",
    "market_train_df = market_train_df.loc[market_train_df['open/close'] > 0.3]\n",
    "print(origlen - len(market_train_df), \"row deleted\")\n",
    "\n",
    "#We are going to be end up generating too many features. generated_non_feature_cols will be used \n",
    "#to filter out unnecessary columns before training starts. (filter by non_feature_cols but adding \n",
    "#columns to generated_non_feature_cols works because non_feature_cols includes generated_non_feature_cols.)\n",
    "\n",
    "target = 'returnsOpenNextMktres10'\n",
    "generated_non_feature_cols = [] # Use it to filter out generated cols that turns out not so useful after analyzing feature importances\n",
    "non_feature_cols = ['assetCode', 'assetName', target, 'time', 'time_x', 'volume_y',] + generated_non_feature_cols\n",
    "new_df = generate_features(market_train_df)\n",
    "\n",
    "market_train_df = pd.merge(market_train_df, new_df, how = 'left', on = ['time', 'assetCode'])\n",
    "del new_df\n",
    "\n",
    "#I am not sure if it is a good thing to use assetCode as a feature, \n",
    "#because it is like an id column and we are putting our model in a risk of overfitting. \n",
    "#If model memorize too much about assetCode and the characteristics of each asset changes \n",
    "#a lot in testing phase, it wouldn't be good. (e.g think about case a company changes \n",
    "#strategy/ceo, reduces outstanding shares etc, it will be very different from training \n",
    "#data even if the code is the same) So it might be good thing to not use 'assetCodeT' \n",
    "#as a feature to avoid overfitting.\n",
    "\n",
    "# label encoding of assetCode\n",
    "def encode_assetCode(market_train):\n",
    "    global code2array_idx\n",
    "    market_train['assetCodeT'] = market_train['assetCode'].map(code2array_idx)\n",
    "    market_train = market_train.dropna(axis=0)\n",
    "    return market_train\n",
    "\n",
    "code2array_idx = dict(\n",
    "    zip(market_train_df.assetCode.unique(), np.arange(market_train_df.assetCode.nunique()))\n",
    ")\n",
    "\n",
    "market_train_df = encode_assetCode(market_train_df)\n",
    "\n",
    "#A lot of news data columns are deleted but let's make use of what's left. \n",
    "#I think sentiment related columns are most important anyways but who knows.\n",
    "\n",
    "def merge_with_news_data(market_df, news_df):\n",
    "    news_df['firstCreated'] = news_df.firstCreated.dt.hour\n",
    "    news_df['assetCodesLen'] = news_df['assetCodes'].map(lambda x: len(eval(x)))\n",
    "    news_df['asset_sentiment_count'] = news_df.groupby(['assetName', 'sentimentClass'])['firstCreated'].transform('count')\n",
    "    # I don't use assetCode for joining key, but use assetName. One news row has multiple assetCode so they don't match nicely with market data\n",
    "    # Also remember assetCodes with same assetName are related assets (normal stock and preferred stock from same company e.g.)\n",
    "    kcol = ['time', 'assetName']\n",
    "    news_df = news_df.groupby(kcol, as_index=False).mean()\n",
    "    market_df = pd.merge(market_df, news_df, how='left', on=kcol, suffixes=(\"\", \"_news\"))\n",
    "    return market_df\n",
    "\n",
    "market_train_df = merge_with_news_data(market_train_df, news_train_df)\n",
    "\n",
    "del news_train_df\n",
    "using(\"Merged news data\")\n",
    "market_train_df.head(3)\n",
    "\n",
    "#Split training and validation data set.\n",
    "\n",
    "y = market_train_df[target] >= 0\n",
    "y = y.values.astype(int)\n",
    "fcol = [c for c in market_train_df if c not in non_feature_cols]\n",
    "\n",
    "X = market_train_df[fcol]\n",
    "print(\"len:\", len(X.columns))\n",
    "for col in X.columns:\n",
    "    print(col, end = ', ')\n",
    "X = X.values\n",
    "\n",
    "# Scaling of X values, Tree based models shouldn't need scaling tho?\n",
    "maxs = np.max(X, axis=0)\n",
    "rng = maxs - np.min(X, axis=0)\n",
    "X = 1 - ((maxs - X) / rng)\n",
    "\n",
    "# Sanity check\n",
    "assert X.shape[0] == y.shape[0]\n",
    "\n",
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X, y, test_size=0.25, random_state=99)\n",
    "\n",
    "del market_train_df, X, y\n",
    "using('done')\n",
    "\n",
    "#Start training of 3 different models. By no means this can be used as benchmark result because only \n",
    "#lgbm is tuned and the others mostly use default paramters. Still it's interesting that XGB stops \n",
    "#training so early on. With current parameters, lgbm works the best in terms of low loss.\n",
    "\n",
    "# Train lgbm\n",
    "\n",
    "lgb_train_data = lgb.Dataset(X_train, label = y_train)\n",
    "lgb_test_data = lgb.Dataset(X_val, label = y_val)\n",
    "\n",
    "params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'learning_rate': 0.19016805202090095,\n",
    "        'num_leaves': 2583,\n",
    "        'min_data_in_leaf': 213,\n",
    "        'num_iteration': 172,\n",
    "        'max_bin': 220,\n",
    "        'seed': 42,\n",
    "    }\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train_data,\n",
    "                valid_sets=lgb_test_data,\n",
    "                early_stopping_rounds=5,\n",
    "                verbose_eval=30,\n",
    "            )\n",
    "\n",
    "del lgb_train_data, lgb_test_data\n",
    "\n",
    "# Train catboost\n",
    "\n",
    "train_pool = catb.Pool(X_train, y_train)\n",
    "validate_pool = catb.Pool(X_val, y_val)\n",
    "\n",
    "catb_model = CatBoostClassifier(\n",
    "    iterations = 300,\n",
    "    random_seed=42,\n",
    ")\n",
    "\n",
    "catb_model.fit(\n",
    "    X_train, y_train.astype(int),\n",
    "    eval_set=(X_val, y_val),\n",
    "    verbose=50,\n",
    "    plot=False\n",
    ")\n",
    "Learning rate set to 0.234294\n",
    "\n",
    "0:\tlearn: 0.6856919\ttest: 0.6856934\tbest: 0.6856934 (0)\ttotal: 304ms\tremaining: 1m 30s\n",
    "50:\tlearn: 0.6486216\ttest: 0.6512860\tbest: 0.6512860 (50)\ttotal: 11.6s\tremaining: 56.5s\n",
    "100:\tlearn: 0.6330856\ttest: 0.6395449\tbest: 0.6395449 (100)\ttotal: 22.9s\tremaining: 45.1s\n",
    "150:\tlearn: 0.6225693\ttest: 0.6319526\tbest: 0.6319526 (150)\ttotal: 33.7s\tremaining: 33.3s\n",
    "200:\tlearn: 0.6128135\ttest: 0.6253607\tbest: 0.6253607 (200)\ttotal: 44.8s\tremaining: 22.1s\n",
    "250:\tlearn: 0.6040755\ttest: 0.6197890\tbest: 0.6197890 (250)\ttotal: 56.4s\tremaining: 11s\n",
    "299:\tlearn: 0.5969309\ttest: 0.6156038\tbest: 0.6156038 (299)\ttotal: 1m 7s\tremaining: 0us\n",
    "\n",
    "bestTest = 0.615603805\n",
    "bestIteration = 299\n",
    "\n",
    "<catboost.core.CatBoostClassifier at 0x7fa0e490ec18>\n",
    "\n",
    "# Train XGB\n",
    "\n",
    "xgb = XGBClassifier(random_state=42) \n",
    "eval_set = [(X_val, y_val)] \n",
    "xgb.fit(X_train, y_train, eval_metric=\"logloss\", early_stopping_rounds=5, eval_set=eval_set, verbose=True)\n",
    "\n",
    "#Now that training is finished, let's check how many features we have and what percentage of contribution \n",
    "#each feature makes on average. If some features are contributing below average you might consider getting \n",
    "#rid of those features.\n",
    "\n",
    "print(\"total features:\", len(fcol), \", average:\", 100/len(fcol))\n",
    "total features: 270 , average: 0.37037037037037035\n",
    "\n",
    "#Now let's check the feature importance. When we have too many features, I find it it's not so useful to \n",
    "#draw graph because feature names are so crammed and hard to read. So I print features in the order of \n",
    "#importance and in terms of percentage of total feature importance. It is intereting to see each model \n",
    "#views feature importances slightly differently.\n",
    "\n",
    "def show_feature_importances(feature_importances):\n",
    "    total_feature_importances = sum(feature_importances)\n",
    "    assert len(feature_importances) == len(fcol) # sanity check\n",
    "    for score, feature_name in sorted(zip(feature_importances, fcol), reverse=True):\n",
    "        print('{}: {}'.format(feature_name, score/total_feature_importances * 100))\n",
    "# lgbm importances split\n",
    "show_feature_importances(gbm.feature_importance(importance_type='split'))\n",
    "\n",
    "# Cat boost feature importance\n",
    "show_feature_importances(catb_model.get_feature_importance(train_pool))\n",
    "\n",
    "# XGB feature importance\n",
    "show_feature_importances(xgb.feature_importances_)\n",
    "\n",
    "# Another standard for deciding feature importance\n",
    "# lgbm importances gain\n",
    "# show_feature_importances(gbm.feature_importance(importance_type='gain'))\n",
    "Having too many features don't always help. It can make it harder for models to train or sometimes lead them to overfit. Let's get some list of features whose importance is way below average(0.37%). Use percentage threshold to set the bar. Whopping 123 features have less than 0.1% importance. Remember you can add these colums to generated_non_feature_cols list and run the kernel again to use only important enough columns.\n",
    "\n",
    "def get_non_important_features(feature_importances, threshold):\n",
    "    total_feature_importances = sum(feature_importances)\n",
    "    assert len(feature_importances) == len(fcol) # sanity check\n",
    "    return [feature_name for score, feature_name in sorted(zip(feature_importances, fcol), reverse=True) if ((score * 100) / total_feature_importances)  < threshold]\n",
    "\n",
    "non_features = get_non_important_features(gbm.feature_importance(importance_type='split'), threshold = 0.1)\n",
    "print(len(non_features))\n",
    "non_features\n",
    "\n",
    "# Other standards for deciding feature importance\n",
    "# print(get_non_important_features(gbm.feature_importance(importance_type='gain'), threshold = 0.1))\n",
    "# print(get_non_important_features(catb_model.get_feature_importance(train_pool), threshold = 0.1))\n",
    "# print(get_non_important_features(xgb.feature_importances_, threshold = 0.1))\n",
    "\n",
    "#This kernel only focuses on various experimental features generation, checking their importances, \n",
    "#how to filter out non-important features. Not all the features generated are useful. \n",
    "#However, it is easy to exclude features using generated_non_feature_cols variable. \n",
    "#I can imagine there can be many more interesting features than I experimented here. \n",
    "#What were some of your favorite features that you created? Let me know. Thank you for reading.\n",
    "\n",
    "using('finished!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
